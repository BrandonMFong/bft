#!/usr/bin/python3

__author__ = "brando"
__date__ = "12/2/24"

import sys
import os
import requests
import json
import tarfile
import platform
import shutil
import dmglib

from arguments import *
from utils import *

ARGS = Arguments()

# gets modified by Arguments() constructor when user
# passes a verbose argument
#VERBOSE = False

def bft_print(buf):
    print("{}".format(buf))

def debug_print(buf):
    """
    conditional print on verbose flag
    """
    if ARGS.debug_print():
        print("bft_debug> {}".format(buf))

def bft_reg_url():
    """
    raw root folder to buckets
    """
    return "https://raw.githubusercontent.com/BrandonMFong/bft-buckets/refs/heads/dev/buckets/"

def bft_api_list_repo():
    """
    https://docs.github.com/en/rest/git/trees?apiVersion=2022-11-28#get-a-tree
    """
    return "https://api.github.com/repos/BrandonMFong/bft-buckets/git/trees/dev?recursive=1"

class Package():
    """
    The package file that gets downloaded from download entry
    """
    def __init__(self, file_path):
        self._file_path = file_path

    def extract(self, target_dir):
        """
        extracts everything in the package file
        """
        debug_print("extracting {} to {}".format(self._file_path, target_dir))
        if self._file_path.endswith("tar.gz"):
            debug_print("identified as a tar.gz file")
            tar = tarfile.open(self._file_path, "r:gz")
            debug_print(tar.getmembers())
            tar.extractall(path=target_dir)
            tar.close()
        elif self._file_path.endswith(".dmg"):
            dmg = dmglib.DiskImage(self._file_path)
            if dmg.has_license_agreement():
                raise Exception("cannot open {}".format(self._file_path))

            for mount_point in dmg.attach():
                shutil.copytree(mount_point, os.path.join(
                    target_dir, os.path.basename(mount_point)
                ))

            dmg.detach()

class BucketMeta():
    """
    Handles parsing the bucket recipe
    """
    def __init__(self, bucket_file_url):
        self._bucket_file_url = bucket_file_url

    def bucket_file_url(self):
        return self._bucket_file_url

    def get_meta(self):
        """
        compiles all the meta data from the bft-buckets buckets directory and
        every buckets' meta url
        """
        url = self._bucket_file_url
        debug_print("downloading bucket description from url {}".format(url))
        headers = {'Cache-Control': 'no-cache'}
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            raise Exception("status code {}".format(response.status_code))
        
        debug_print("bucket content:")
        self._meta_bucket = response.json()
        debug_print(json.dumps(self._meta_bucket, indent=4))

        meta_url = response.json()["meta"]["url"]
        response = requests.get(meta_url, headers=headers)
        debug_print("downloading bucket metadata from url {}".format(meta_url))
        if response.status_code != requests.codes.ok:
            response.raise_for_status()


        debug_print("meta data:")
        self._meta_github_release = response.json()
        debug_print(json.dumps(self._meta_github_release, indent=4))

    def meta_bucket(self):
        """
        json object holding objects like the ones here:
        https://github.com/BrandonMFong/bft-buckets/tree/dev/buckets
        """
        return self._meta_bucket

    def tag_name(self):
        """
        returns tag_name from the github latest release api
        """
        return self._meta_github_release["tag_name"]

    def __platform(self):
        """
        returns the download's subkey that determines
        what package to download for the current platform
        """
        if platform.system() == "Linux":
            return "linux"
        elif platform.system() == "Darwin":
            return "macos"

    def url_package(self):
        """
        download url
        """
        platform = self.__platform()
        return self._meta_bucket["download"][platform]["url"]

    def package_items(self):
        """
        items from the package we are extracting
        """
        platform = self.__platform()
        return self._meta_bucket["download"][platform]["items"]

class Bucket():
    """
    A bucket is the package that we are installing/updating
    """
    def __init__(self, name):
        self._name = name
        self._meta = BucketMeta(bft_reg_url() + self._name + ".json")

    def fetch(self):
        """
        fetches remote data
        """
        self._meta.get_meta()

    def tag_name(self):
        """
        tag_name is the version
        returns the tag_name set for the release
        """
        return self._meta.tag_name()

    def name(self):
        """
        name of the bucket. Usually the basename of the
        bucket file without the extension
        """
        return self._name

    def __url_package(self):
        """
        the url entry under meta
        """
        return self._meta.url_package()

    def download(self, pool_dir):
        """
        downloads the package
        """
        # create tmp directory we are downloading to
        debug_print("downloading to pool_dir {}...".format(pool_dir))
        tmp_dir = os.path.join(pool_dir, "tmp")
        shutil.rmtree(tmp_dir, ignore_errors=True)
        create_dir(tmp_dir)

        # get the url we are downloading from
        url = self.__url_package()
        tmp_file = tmp_dir + "/" + os.path.basename(url)
        debug_print("downloading {} to {}".format(
            url, tmp_file
        ))

        # get the object from url
        # fetch with progress
        debug_print("fetching {}".format(url))
        headers = {'Cache-Control': 'no-cache'}
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            raise Exception("status code {}".format(response.status_code))

        # write content to a file
        with open(tmp_file, mode="wb") as file:
            file.write(response.content)

        if os.path.getsize(tmp_file) == 0:
            raise Exception("{} is empty".format(tmp_file))

        # extract items from package file
        bucket_pkg = Package(tmp_file)
        bucket_pkg.extract(tmp_dir)
        bin_dir = os.path.join(pool_dir, "bin")
        create_dir(bin_dir)
        for item in self._meta.package_items():
            src = os.path.join(tmp_dir, item)
            dest = os.path.join(bin_dir, os.path.basename(item))
            debug_print("{} -> {}".format(src, dest))
            os.rename(src, dest)

    def __meta_bucket_saved_content(self):
        """
        adds an 'installed' entry to cache some meta data before we fetch it
        """
        res = self._meta.meta_bucket()

        res["installed"] = {"tag_name" : self.tag_name()}

        return res

    def save(self, pool_dir):
        """
        saves the bucket json file to .installed directory
        in the pool directory
        """
        debug_print("saving bucket")
        installed_dir = os.path.join(pool_dir, ".installed")
        create_dir(installed_dir)
        debug_print("saving bucket into dir {}".format(installed_dir))

        meta_bucket_json_file = os.path.join(
            installed_dir,
            os.path.basename(self._meta.bucket_file_url())
        )

        meta_bucket_json_content = json.dumps(
            self.__meta_bucket_saved_content(), indent=4
        )

        debug_print("preparing to write to file '{}':".format(meta_bucket_json_file))
        debug_print(meta_bucket_json_content)
        with open(meta_bucket_json_file, 'w') as f:
            f.write(meta_bucket_json_content)

    def is_installed(self, pool_dir):
        """
        checks local system for a saved meta bucket file

        this function should not require or do any remote requests
        """
        debug_print("checking if {} is installed".format(self.name()))
        installed_dir = os.path.join(pool_dir, ".installed")

        meta_bucket_json_file = os.path.join(
            installed_dir,
            os.path.basename(self._meta.bucket_file_url())
        )

        return os.path.isfile(meta_bucket_json_file)

    def can_update(self, pool_dir):
        """
        compares our tag_name with the saved tag_name in
        the .installed directory
        """
        debug_print("checking if {} is can be updated".format(self.name()))
        installed_dir = os.path.join(pool_dir, ".installed")

        meta_bucket_json_file = os.path.join(
            installed_dir,
            os.path.basename(self._meta.bucket_file_url())
        )

        if os.path.isfile(meta_bucket_json_file) is False:
            raise Exception("{} does not exist".format(
                meta_bucket_json_file
            ))

        with open(meta_bucket_json_file, 'r') as f:
            data = json.load(f)
            tag_name = data["installed"]["tag_name"]
            return tag_name != self.tag_name()

        return False

    def uninstall(self, pool_dir):
        debug_print("uninstalling...")
 
def create_dir(d):
    """
    creates directory if it doesn't exist
    """
    debug_print("creating directory '{}'".format(d))
    try:
        os.mkdir(d)
    except:
        pass

def install_exec():
    """
    does installation
    """
    debug_print("installing...")
    debug_print("bucket to install {}".format(ARGS.install_targets))
 
    pool_dir = get_pool_dir()
    create_dir(pool_dir)

    for bucket_name in ARGS.install_targets():
        remote_bucket = Bucket(bucket_name)
      
        if remote_bucket.is_installed(pool_dir):
            bft_print("{} is already installed".format(remote_bucket.name()))
            continue

        debug_print("not installed so we are going to fetch")
        remote_bucket.fetch()
        debug_print("remote bucket tag_name: {}".format(remote_bucket.tag_name()))
 
        remote_bucket.download(pool_dir)

        remote_bucket.save(pool_dir)

        bft_print("installed {}".format(bucket_name))

def list_exec_print_bucket(name, is_installed):
    bft_print("{} {}".format(name, "(installed)" if is_installed else ""))

def list_exec():
    """
    lists available buckets and if they are installed
    """
    debug_print("listing...")
    pool_dir = get_pool_dir()

    # fetch the repo tree
    url = bft_api_list_repo()
    headers = {'Cache-Control': 'no-cache'}
    response = requests.get(url, headers=headers)
    if response.status_code != requests.codes.ok:
        response.raise_for_status()

    repo_tree_json = response.json()
    debug_print("raw bft-buckets repo tree:")
    debug_print(json.dumps(repo_tree_json, indent=4))

    debug_print("going through the buckets directory from remote repo")
    for item in repo_tree_json["tree"]:
        path = item["path"]
        if os.path.dirname(path) == "buckets":
            debug_print("relative path: '{}'".format(path))
            bucket_name = os.path.basename(path)
            bucket_name = os.path.splitext(bucket_name)[0]
            debug_print("  file name: '{}'".format(bucket_name))

            remote_bucket = Bucket(bucket_name)
            #remote_bucket.fetch()
            list_exec_print_bucket(
                remote_bucket.name(),
                remote_bucket.is_installed(pool_dir)
            )

def update_exec():
    """
    performs an update on the update targets

    we perform an update by doing things similar to
    installation: download and save. Essentially
    overwriting the content
    """
    debug_print("updating...")
    pool_dir = get_pool_dir()
    create_dir(pool_dir)

    for bucket_name in ARGS.update_targets():
        remote_bucket = Bucket(bucket_name)
      
        if remote_bucket.is_installed(pool_dir) is False:
            bft_print(
                "{} - not installed".format(
                    remote_bucket.name()
            ))
            continue

        debug_print("bucket is installed so we will fetch from remote for updated data")
        remote_bucket.fetch()
        debug_print("remote bucket tag_name: {}".format(remote_bucket.tag_name()))
 
        if remote_bucket.can_update(pool_dir):
            remote_bucket.download(pool_dir)
            remote_bucket.save(pool_dir)
            bft_print("{} - updated".format(bucket_name))
        else:
            bft_print("{} - up to date".format(
                remote_bucket.name()
            ))

def main():
    #args = Arguments()
    
    if ARGS.show_help():
        Arguments.print_help()
    elif ARGS.do_install():
        install_exec()
    elif ARGS.do_update():
        update_exec()
    elif ARGS.do_list():
        list_exec()

if __name__ == "__main__":
    main()

